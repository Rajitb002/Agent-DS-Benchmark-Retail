{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ef7abb0-a547-4338-af77-f0dafe9cf6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "015b7f95-0526-49cb-86a4-e4c49d1a267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_panel_df = pd.read_csv('/home/jovyan/shared/datasets/RetailBanking/customer_panel_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c7184e-6b4d-43d7-bf4e-5df1b819e31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Proportion of customers who default: 0.09232388542214871\n",
      " Proportion of customers who do not default: 0.9076761145778512\n"
     ]
    }
   ],
   "source": [
    "# What are the proportions of the responses?\n",
    "n = customer_panel_df.shape[0]\n",
    "prop_default = (customer_panel_df['DefaultLabel'] == 1).sum() / n\n",
    "print(f' Proportion of customers who default: {prop_default}')\n",
    "print(f' Proportion of customers who do not default: {1-prop_default}')\n",
    "# Dataset is extremely imbalanced - only 9.2% of customers in the data default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78fc81a8-fd89-4daa-a263-12ed03573059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9310\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import train and test data\n",
    "train_data = pd.read_csv('interactions_train.csv')\n",
    "#train_data = pd.read_csv('customer_panel_train_merge.csv')\n",
    "\n",
    "# For SMOTE:\n",
    "smote = SMOTE(random_state=42, k_neighbors=5, sampling_strategy=0.5)\n",
    "#train_data = train_data.fillna(-1)\n",
    "\n",
    "features = ['PaymentRatio', 'TotalBalance', 'Limit',\n",
    "             'Age', 'CreditScore', 'AnnualSalary', 'Utilisation', 'HardInquiries']\n",
    "engineered_features = ['balance_to_limit',\n",
    "                       'missed_payment_flag', 'total_accounts',\n",
    "                       'credit_to_savings_ratio', 'balance_to_salary',\n",
    "                       'limit_to_salary', 'payment_to_salary_ratio',\n",
    "                        'SalaryBalance', 'SalaryCredit',\n",
    "                      'CreditSquared', 'AgeCredit', 'AgeSalary', 'AgeBalance',\n",
    "                       'PrevInquiries', 'LaggedUtilisation', 'LaggedPaymentRatio',\n",
    "                       'RollingUtil', 'RollingPayRatio'] #\n",
    "features = features + engineered_features\n",
    "\n",
    "X_train_df = train_data[features]\n",
    "y_train_df = train_data['DefaultLabel']\n",
    "X, y = X_train_df.to_numpy(), y_train_df.to_numpy()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "test_data = pd.read_csv('interactions_test.csv')\n",
    "X_test_df = test_data[features]\n",
    "X_test = X_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape[0])\n",
    "#X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ece0abf-9b36-4eae-9d17-5bbaec9c0201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale weight value = 9.825581395348838\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "----------------------------------------\n",
      "Best xgb F1-Score on Training Set: 0.9543133064414879\n",
      "Best xgb Precision on Training Set: 0.8481262327416174\n",
      "Best xgb Recall on Training Set: 1.0\n",
      "----------------------------------------\n",
      "Best xgb F1-Score on Validation Set: 0.94160948858746\n",
      "Best xgb Precision on Validation Set: 0.848780487804878\n",
      "Best xgb Recall on Validation Set: 0.9456521739130435\n",
      "----------------------------------------\n",
      "Best xgb Parameters:  {'eta': 0.01, 'max_depth': 7, 'n_estimators': 900, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "## CV on XGB\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "neg_count = np.sum(y_train == 0)\n",
    "pos_count = np.sum(y_train == 1)\n",
    "scale_pos_weight = neg_count / pos_count # square root can be used if scale_pos_weight is too high\n",
    "print(f'Scale weight value = {scale_pos_weight}')\n",
    "\n",
    "# Define parameters for the xgboost model\n",
    "params = {'objective':'binary:logistic',\n",
    "          'eval_metric':'aucpr',\n",
    "          'random_state':42,\n",
    "          'scale_pos_weight': scale_pos_weight, # comment out if using smote\n",
    "          'colsample_bylevel':1.0,\n",
    "          'colsample_bynode':1.0\n",
    "         }\n",
    "\n",
    "# Define parameters to test using CV\n",
    "param_grid = {'n_estimators':[700,800,900],\n",
    "              'subsample':[0.6,0.7,0.8],\n",
    "              'eta':[0.01,0.1],\n",
    "              'max_depth':[5,6,7],\n",
    "             }\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "xgb = XGBClassifier(**params)\n",
    "\n",
    "# Perform CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "#grid_search.fit(X_train_smote, y_train_smote)\n",
    "xgb_best = grid_search.best_estimator_\n",
    "\n",
    "y_hat_train = xgb_best.predict(X_train)\n",
    "y_hat_val = xgb_best.predict(X_val)\n",
    "\n",
    "F1_train = f1_score(y_train, y_hat_train, average='macro')\n",
    "precision_train = precision_score(y_train, y_hat_train)\n",
    "recall_train = recall_score(y_train, y_hat_train)\n",
    "\n",
    "F1_val = f1_score(y_val, y_hat_val, average='macro')\n",
    "precision_val = precision_score(y_val, y_hat_val)\n",
    "recall_val = recall_score(y_val, y_hat_val)\n",
    "\n",
    "print('----------------------------------------')\n",
    "print(f'Best xgb F1-Score on Training Set: {F1_train}')\n",
    "print(f'Best xgb Precision on Training Set: {precision_train}')\n",
    "print(f'Best xgb Recall on Training Set: {recall_train}')\n",
    "print('----------------------------------------')\n",
    "print(f'Best xgb F1-Score on Validation Set: {F1_val}')\n",
    "print(f'Best xgb Precision on Validation Set: {precision_val}')\n",
    "print(f'Best xgb Recall on Validation Set: {recall_val}')\n",
    "print('----------------------------------------')\n",
    "print('Best xgb Parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a03d34-f977-4b20-ae24-c593083a5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_best.save_model('C2BestXGB2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50ab8fcb-3d7e-4094-86b1-da5e8a9708b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "----------------------------------------\n",
      "Best rf F1-Score on Training Set: 0.9585967413687593\n",
      "Best rf Precision on Training Set: 0.9611041405269761\n",
      "Best rf Recall on Training Set: 0.8906976744186047\n",
      "----------------------------------------\n",
      "Best rf F1-Score on Validation Set: 0.9439172225136776\n",
      "Best rf Precision on Validation Set: 0.9404761904761905\n",
      "Best rf Recall on Validation Set: 0.8586956521739131\n",
      "----------------------------------------\n",
      "Best rf Parameters:  {'max_depth': 11, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## CV on RF\n",
    "\n",
    "# Instantiate model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameters to test using CV\n",
    "param_grid = {'max_depth': [8,9,10,11], \n",
    "             'min_samples_leaf': [1],\n",
    "             'min_samples_split': [4],\n",
    "             'max_features': [3,4,5,6],\n",
    "             'n_estimators': [400,500,600]}  \n",
    "\n",
    "# Perform CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "rf_best = grid_search.best_estimator_\n",
    "\n",
    "y_hat_train = rf_best.predict(X_train)\n",
    "y_hat_val = rf_best.predict(X_val)\n",
    "\n",
    "F1_train = f1_score(y_train, y_hat_train, average='macro')\n",
    "precision_train = precision_score(y_train, y_hat_train)\n",
    "recall_train = recall_score(y_train, y_hat_train)\n",
    "\n",
    "F1_val = f1_score(y_val, y_hat_val, average='macro')\n",
    "precision_val = precision_score(y_val, y_hat_val)\n",
    "recall_val = recall_score(y_val, y_hat_val)\n",
    "print('----------------------------------------')\n",
    "print(f'Best rf F1-Score on Training Set: {F1_train}')\n",
    "print(f'Best rf Precision on Training Set: {precision_train}')\n",
    "print(f'Best rf Recall on Training Set: {recall_train}')\n",
    "print('----------------------------------------')\n",
    "print(f'Best rf F1-Score on Validation Set: {F1_val}')\n",
    "print(f'Best rf Precision on Validation Set: {precision_val}')\n",
    "print(f'Best rf Recall on Validation Set: {recall_val}')\n",
    "print('----------------------------------------')\n",
    "print('Best rf Parameters: ', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da38cb64-b36b-467f-b73b-ff6feb838bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in /home/jovyan/.local/lib/python3.11/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/jovyan/.local/lib/python3.11/site-packages (from lightgbm) (2.3.4)\n",
      "Requirement already satisfied: scipy in /home/jovyan/.local/lib/python3.11/site-packages (from lightgbm) (1.16.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9d7097c-bbbe-4a5c-aa52-f64a0c6e9d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "need to call fit or load_model beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate performance on train and validation sets using Macro F1-Score\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_hat_train \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_hat_val \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m      5\u001b[0m F1_train \u001b[38;5;241m=\u001b[39m f1_score(y_train, y_hat_train, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1839\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1836\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1837\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1839\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1847\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/core.py:774\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    773\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1443\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1443\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minplace_predict(\n\u001b[1;32m   1444\u001b[0m             data\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   1445\u001b[0m             iteration_range\u001b[38;5;241m=\u001b[39miteration_range,\n\u001b[1;32m   1446\u001b[0m             predict_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1447\u001b[0m             missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1448\u001b[0m             base_margin\u001b[38;5;241m=\u001b[39mbase_margin,\n\u001b[1;32m   1449\u001b[0m             validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[1;32m   1450\u001b[0m         )\n\u001b[1;32m   1451\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1452\u001b[0m             cp \u001b[38;5;241m=\u001b[39m import_cupy()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/xgboost/sklearn.py:1009\u001b[0m, in \u001b[0;36mXGBModel.get_booster\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__():\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to call fit or load_model beforehand\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\n",
      "\u001b[0;31mNotFittedError\u001b[0m: need to call fit or load_model beforehand"
     ]
    }
   ],
   "source": [
    "# Evaluate performance on train and validation sets using Macro F1-Score\n",
    "y_hat_train = xgb.predict(X_train)\n",
    "y_hat_val = xgb.predict(X_val)\n",
    "\n",
    "F1_train = f1_score(y_train, y_hat_train, average='macro')\n",
    "precision_train = precision_score(y_train, y_hat_train)\n",
    "recall_train = recall_score(y_train, y_hat_train)\n",
    "\n",
    "F1_val = f1_score(y_val, y_hat_val, average='macro')\n",
    "precision_val = precision_score(y_val, y_hat_val)\n",
    "recall_val = recall_score(y_val, y_hat_val)\n",
    "\n",
    "print(f'F1-Score on Training Set: {F1_train}')\n",
    "print(f'Precision on Training Set: {precision_train}')\n",
    "print(f'Recall on Training Set: {recall_train}')\n",
    "print('--------------------------------')\n",
    "print(f'F1-Score on Validation Set: {F1_val}')\n",
    "print(f'Precision on Validation Set: {precision_val}')\n",
    "print(f'Recall on Validation Set: {recall_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86feb2ed-46e0-4f8f-b4a7-1ec580ec695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Predictions saved: 13290 predictions\n",
      "   Preview:   CustomerID  Week  DefaultLabel\n",
      "0    C000001     1             0\n",
      "1    C000001     2             0\n",
      "2    C000001     3             0\n",
      "   Default rate: 0.038 (500 defaults out of 13290)\n"
     ]
    }
   ],
   "source": [
    "from agentds import BenchmarkClient\n",
    "\n",
    "# Generate submission file\n",
    "client = BenchmarkClient(\n",
    "    api_key=\"adsb_hdm1DRk1iW2I1VA84Oc9jz6z_1756090832\",\n",
    "    team_name=\"agi\"\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "predictions = rf_best.predict(X_test)\n",
    "\n",
    "# Create submission file (format: CustomerID,Week,DefaultLabel)\n",
    "submission_df = pd.DataFrame({\n",
    "    'CustomerID': test_data['CustomerID'],\n",
    "    'Week': test_data['Week'],\n",
    "    'DefaultLabel': predictions\n",
    "})\n",
    "\n",
    "# Save predictions\n",
    "submission_df.to_csv(\"retailbanking_challenge2_predictions.csv\", index=False)\n",
    "print(f\"âœ… Predictions saved: {submission_df.shape[0]} predictions\")\n",
    "print(f\"   Preview: {submission_df.head(3)}\")\n",
    "print(f\"   Default rate: {predictions.mean():.3f} ({predictions.sum()} defaults out of {len(predictions)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba2d6818-ee2f-4699-a9de-58bad8a62a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Submitting predictions...\n",
      "âœ… Prediction submitted successfully!\n",
      "ðŸ“Š Score: 0.6595 (Macro-F1)\n",
      "âœ… Validation passed\n",
      "âœ… Submission successful!\n",
      "   ðŸ“Š Score: 0.6595\n",
      "   ðŸ“ Metric: Macro-F1\n",
      "   âœ”ï¸  Validation: Passed\n",
      "\n",
      "ðŸŽ¯ Next steps:\n",
      "   1. Try incorporating relevant information outside this table!\n",
      "   2. You've completed all Retail Banking challenges!\n"
     ]
    }
   ],
   "source": [
    "# 3. Submit Predictions\n",
    "\n",
    "# Submit predictions to the competition\n",
    "print(\"ðŸš€ Submitting predictions...\")\n",
    "\n",
    "try:\n",
    "    result = client.submit_prediction(\"Retailbanking\", 2, \"retailbanking_challenge2_predictions.csv\")\n",
    "    \n",
    "    if result['success']:\n",
    "        print(\"âœ… Submission successful!\")\n",
    "        print(f\"   ðŸ“Š Score: {result['score']:.4f}\")\n",
    "        print(f\"   ðŸ“ Metric: {result['metric_name']}\")\n",
    "        print(f\"   âœ”ï¸  Validation: {'Passed' if result['validation_passed'] else 'Failed'}\")\n",
    "    else:\n",
    "        print(\"âŒ Submission failed!\")\n",
    "        print(f\"   Error details: {result.get('details', {}).get('validation_errors', 'Unknown error')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ðŸ’¥ Submission error: {e}\")\n",
    "    print(\"ðŸ”§ Check your API key and team name are correct!\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Next steps:\")\n",
    "print(\"   1. Try incorporating relevant information outside this table!\")\n",
    "print(\"   2. You've completed all Retail Banking challenges!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa69a6-b0a3-45eb-bbdc-08e9bbcb2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which of the features are highly correlated with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05e3aef7-5da8-4d3d-b619-e1558333c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation\n",
      "T-Stat: 0.9781635715541426\n",
      "p-val: 0.3280357898449866\n",
      "--------------\n",
      "missed_payment_flag\n",
      "T-Stat: 0.21306032130528654\n",
      "p-val: 0.8312876879453321\n",
      "--------------\n",
      "Contingency Table:\n",
      "DefaultLabel            0    1\n",
      "missed_payment_flag           \n",
      "0                    5271  302\n",
      "1                    6802  926\n",
      "\n",
      "Chi-squared Statistic: 165.66889238284364\n",
      "P-value: 6.534218501583134e-38\n",
      "Degrees of Freedom: 1\n",
      "Expected Frequencies:\n",
      "[[5058.47898654  514.52101346]\n",
      " [7014.52101346  713.47898654]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Which of the features are highly associated with the response?\n",
    "\n",
    "categoricals = ['is_high_inquiry_user', 'is_rapid_credit_growth']\n",
    "# For quantitative predictors use T-test to see if mean values differ across the response\n",
    "for feature in list(set(features)-set(categoricals)):\n",
    "    group1 = train_data[train_data['DefaultLabel']==1].dropna()\n",
    "    group2 = train_data[train_data['DefaultLabel']==0].dropna()\n",
    "    ttest = ttest_ind(group1[feature], group2[feature])\n",
    "    if(ttest.pvalue > 0.05):\n",
    "        print(feature)\n",
    "        print(f'T-Stat: {ttest.statistic}')\n",
    "        print(f'p-val: {ttest.pvalue}')\n",
    "        print('--------------')\n",
    "# Can drop Utilisation, HardInquiries, NumChecking, Tenure, payment_ratio_change, credit_utilization_change, utilization_trend, missed_payment_flag, HomeCity\n",
    "\n",
    "# Chi^2\n",
    "# Create the contingency table\n",
    "# contingency_table = pd.crosstab(train_data['is_high_inquiry_user'], train_data['DefaultLabel']) p = 3e-25\n",
    "# contingency_table = pd.crosstab(train_data['is_rapid_credit_growth'], train_data['DefaultLabel']) p = 0.45\n",
    "#contingency_table = pd.crosstab(train_data['is_high_utilization'], train_data['DefaultLabel'])# p = 1.0\n",
    "contingency_table = pd.crosstab(train_data['missed_payment_flag'], train_data['DefaultLabel'])# p = 0.45\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "chi2_statistic, p_value, degrees_of_freedom, expected_frequencies = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-squared Statistic: {chi2_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected_frequencies)\n",
    "# Can drop is_rapid_credit_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691dab2-96a6-4add-a1e0-cadf7903f720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
