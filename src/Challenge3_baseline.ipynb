{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Insurance Challenge 3 - Baseline Submission\n",
        "\n",
        "This notebook provides a simple baseline for **Insurance Challenge 3: Fraud Detection**.\n",
        "\n",
        "**Goal**: Predict `FraudLabel` (0/1) for each insurance claim\n",
        "**Metric**: Macro-F1 Score - Higher is better\n",
        "\n",
        "## Instructions:\n",
        "1. **Replace API credentials** in the first cell with your team's API key and name\n",
        "2. **Run all cells** to generate and submit baseline predictions\n",
        "3. **Check the output** for your submission score\n",
        "\n",
        "This baseline uses only tabular claim data with a simple Random Forest classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Initialize Client and Load Data\n",
        "!pip install xgboost\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, IsolationForest\n",
        "from agentds import BenchmarkClient\n",
        "\n",
        "# üîë REPLACE WITH YOUR CREDENTIALS\n",
        "client = BenchmarkClient(\n",
        "    api_key=\"your-api-key-here\",        # Get from your team dashboard\n",
        "    team_name=\"your-team-name-here\"     # Your exact team name\n",
        ")\n",
        "\n",
        "# Load data from PVC paths\n",
        "print(\"üìÇ Loading Insurance Challenge 3 data...\")\n",
        "\n",
        "# Load claim data\n",
        "train_claims = pd.read_csv(\"/home/jovyan/shared/datasets/Insurance/train_claims.csv\")\n",
        "test_claims = pd.read_csv(\"/home/jovyan/shared/datasets/Insurance/test_claims.csv\")\n",
        "\n",
        "print(f\"‚úÖ Data loaded:\")\n",
        "print(f\"   Train claims: {train_claims.shape}\")\n",
        "print(f\"   Test claims: {test_claims.shape}\")\n",
        "print(f\"   Train columns: {list(train_claims.columns)}\")\n",
        "print(f\"   Test columns: {list(test_claims.columns)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Tabular-Only Baseline Model and Predictions\n",
        "\n",
        "# From data inspection - meaningful claim features available in test data:\n",
        "# ReportedDamage, NumParties, ClaimType, FraudLabel (train only)\n",
        "\n",
        "# Select meaningful features for baseline (excluding PolicyID - just an identifier)\n",
        "claim_features = ['ReportedDamage', 'NumParties', 'ClaimType']\n",
        "print(f\"üìä Using claim features: {claim_features}\")\n",
        "\n",
        "# Prepare training data with categorical encoding\n",
        "X_train = train_claims[claim_features].copy()\n",
        "# Encode categorical variable\n",
        "X_train['ClaimType_encoded'] = pd.Categorical(X_train['ClaimType']).codes\n",
        "X_train = X_train[['ReportedDamage', 'NumParties', 'ClaimType_encoded']].fillna(0)\n",
        "y_train = train_claims['FraudLabel']  # Binary target (0/1)\n",
        "\n",
        "# Prepare test data with same encoding\n",
        "X_test = test_claims[claim_features].copy()\n",
        "# Use same categorical encoding as training\n",
        "X_test['ClaimType_encoded'] = pd.Categorical(X_test['ClaimType']).codes\n",
        "X_test = X_test[['ReportedDamage', 'NumParties', 'ClaimType_encoded']].fillna(0)\n",
        "\n",
        "# Train simple Random Forest baseline\n",
        "print(\"ü§ñ Training Random Forest classifier...\")\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Create submission file (format: ClaimID,FraudLabel)\n",
        "submission_df = pd.DataFrame({\n",
        "    'ClaimID': test_claims['ClaimID'],\n",
        "    'FraudLabel': predictions\n",
        "})\n",
        "\n",
        "# Save predictions\n",
        "submission_df.to_csv(\"insurance_challenge3_predictions.csv\", index=False)\n",
        "print(f\"‚úÖ Predictions saved: {submission_df.shape[0]} predictions\")\n",
        "print(f\"   Preview: {submission_df.head(3)}\")\n",
        "print(f\"   Fraud rate: {predictions.mean():.3f} ({predictions.sum()} fraudulent out of {len(predictions)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Submit Predictions\n",
        "\n",
        "# Submit predictions to the competition\n",
        "print(\"üöÄ Submitting predictions...\")\n",
        "\n",
        "try:\n",
        "    result = client.submit_prediction(\"Insurance\", 3, \"insurance_challenge3_predictions.csv\")\n",
        "    \n",
        "    if result['success']:\n",
        "        print(\"‚úÖ Submission successful!\")\n",
        "        print(f\"   üìä Score: {result['score']:.4f}\")\n",
        "        print(f\"   üìè Metric: {result['metric_name']}\")\n",
        "        print(f\"   ‚úîÔ∏è  Validation: {'Passed' if result['validation_passed'] else 'Failed'}\")\n",
        "    else:\n",
        "        print(\"‚ùå Submission failed!\")\n",
        "        print(f\"   Error details: {result.get('details', {}).get('validation_errors', 'Unknown error')}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"üí• Submission error: {e}\")\n",
        "    print(\"üîß Check your API key and team name are correct!\")\n",
        "\n",
        "print(\"\\nüéØ Next steps:\")\n",
        "print(\"   1. Try incorporating relevant information outside this table!\")\n",
        "print(\"   2. You've completed all Insurance challenges!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
